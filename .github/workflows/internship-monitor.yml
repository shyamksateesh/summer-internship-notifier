name: Internship Monitor

on:
  schedule:
    # Runs every hour at minute 0
    - cron: '0 * * * *'
  workflow_dispatch: # Allows manual triggering for testing

jobs:
  check-for-updates:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout monitoring repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Fetch latest internship data
        run: |
          # Fetch the README from the internships repository
          curl -H "Accept: application/vnd.github.v3.raw" \
               -o new_readme.md \
               https://api.github.com/repos/SimplifyJobs/Summer2026-Internships/readme
          
          # Fetch the last commit info for the README
          curl -H "Accept: application/vnd.github.v3+json" \
               -o latest_commit.json \
               https://api.github.com/repos/SimplifyJobs/Summer2026-Internships/commits?path=README.md&per_page=1
      
      - name: Analyze changes and detect new internships
        id: analyze
        run: |
          python3 << 'PYTHON_SCRIPT'
          import re
          import json
          import sys
          from datetime import datetime
          
          print("Starting analysis...")
          
          # Read the previous and new README files
          try:
              with open('previous_readme.md', 'r', encoding='utf-8') as f:
                  previous_content = f.read()
              print(f"Previous README loaded: {len(previous_content)} characters")
          except FileNotFoundError:
              print("First run - no previous data")
              previous_content = ""
          
          with open('new_readme.md', 'r', encoding='utf-8') as f:
              new_content = f.read()
          print(f"New README loaded: {len(new_content)} characters")
          
          # Read commit info
          with open('latest_commit.json', 'r') as f:
              commit_data = json.load(f)[0]
              commit_message = commit_data['commit']['message']
              commit_date = commit_data['commit']['author']['date']
              commit_sha = commit_data['sha'][:7]
          
          print(f"Commit info: {commit_sha} - {commit_message}")
          
          def extract_section(content, section_title):
              """Extract a specific section from the README - FAST VERSION"""
              print(f"Extracting section: {section_title}")
              
              # Find start of section
              start_pattern = f'## {re.escape(section_title)}'
              start_match = re.search(start_pattern, content)
              if not start_match:
                  print(f"  Section not found!")
                  return ""
              
              start_pos = start_match.start()
              
              # Find next section (starts with ##)
              next_section = re.search(r'\n## ', content[start_pos + len(start_pattern):])
              if next_section:
                  end_pos = start_pos + len(start_pattern) + next_section.start()
              else:
                  end_pos = len(content)
              
              section = content[start_pos:end_pos]
              print(f"  Extracted {len(section)} characters")
              return section
          
          def parse_internships_fast(section_content):
              """Parse internship entries - OPTIMIZED VERSION"""
              print("  Parsing internships...")
              internships = set()
              
              # Split into table rows first (much faster)
              rows = section_content.split('<tr>')
              print(f"  Found {len(rows)} rows")
              
              count = 0
              for row in rows[1:]:  # Skip header row
                  # Quick check if this is a main company row (not a ‚Ü≥ continuation)
                  if '‚Ü≥' in row or '<strong>' not in row:
                      continue
                  
                  try:
                      # Extract company (between <strong> tags)
                      company_match = re.search(r'<strong>.*?>(.*?)</a></strong>', row)
                      if not company_match:
                          continue
                      company = re.sub(r'<.*?>', '', company_match.group(1)).strip()
                      
                      # Extract role (second <td>)
                      role_match = re.search(r'</strong>.*?<td>(.*?)</td>', row)
                      if not role_match:
                          continue
                      role = re.sub(r'<.*?>', '', role_match.group(1)).strip()
                      
                      # Extract location (third <td>)
                      location_match = re.search(r'<td>.*?</td>.*?<td>(.*?)</td>', row)
                      if not location_match:
                          continue
                      location = re.sub(r'<.*?>', '', location_match.group(1)).strip()
                      location = location.replace('</br>', ', ')
                      
                      # Extract application link (look for first href before "Apply")
                      link_match = re.search(r'href="([^"]+)"[^>]*>.*?Apply', row)
                      app_link = link_match.group(1).strip() if link_match else ""
                      
                      if company and role:
                          internships.add(f"{company}|{role}|{location}|{app_link}")
                          count += 1
                  except Exception as e:
                      # Skip malformed rows silently
                      continue
              
              print(f"  Parsed {count} internships")
              return internships
          
          # Extract relevant sections
          print("\n--- Extracting Software Engineering section ---")
          swe_section_old = extract_section(previous_content, "üíª Software Engineering Internship Roles")
          swe_section_new = extract_section(new_content, "üíª Software Engineering Internship Roles")
          
          print("\n--- Extracting AI/ML/DS section ---")
          ai_section_old = extract_section(previous_content, "ü§ñ Data Science, AI & Machine Learning Internship Roles")
          ai_section_new = extract_section(new_content, "ü§ñ Data Science, AI & Machine Learning Internship Roles")
          
          # Parse internships
          print("\n--- Parsing Software Engineering internships ---")
          swe_internships_old = parse_internships_fast(swe_section_old)
          swe_internships_new = parse_internships_fast(swe_section_new)
          
          print("\n--- Parsing AI/ML/DS internships ---")
          ai_internships_old = parse_internships_fast(ai_section_old)
          ai_internships_new = parse_internships_fast(ai_section_new)
          
          # Find new internships
          print("\n--- Finding new internships ---")
          new_swe = swe_internships_new - swe_internships_old
          new_ai = ai_internships_new - ai_internships_old
          
          print(f"New SWE: {len(new_swe)}, New AI/ML/DS: {len(new_ai)}")
          
          # Check if there are any new relevant internships
          if new_swe or new_ai:
              print(f"\n‚úÖ Found {len(new_swe)} new SWE internships and {len(new_ai)} new AI/ML/DS internships")
              
              # Format the email body
              email_body = f"üéâ New internship opportunities have been posted!\n\n"
              email_body += f"üìÖ Last Updated: {commit_date}\n"
              email_body += f"üí¨ Latest Commit: {commit_message}\n"
              email_body += f"üîó Commit SHA: {commit_sha}\n\n"
              
              if new_swe:
                  email_body += f"üíª NEW SOFTWARE ENGINEERING ROLES ({len(new_swe)}):\n"
                  email_body += "=" * 70 + "\n\n"
                  for i, internship in enumerate(sorted(new_swe), 1):
                      parts = internship.split('|')
                      company = parts[0]
                      role = parts[1]
                      location = parts[2]
                      app_link = parts[3] if len(parts) > 3 else ""
                      
                      email_body += f"{i}. {company}\n"
                      email_body += f"   Role: {role}\n"
                      email_body += f"   Location: {location}\n"
                      if app_link:
                          email_body += f"   üîó Apply: {app_link}\n"
                      email_body += "\n"
              
              if new_ai:
                  email_body += f"\nü§ñ NEW AI/ML/DATA SCIENCE ROLES ({len(new_ai)}):\n"
                  email_body += "=" * 70 + "\n\n"
                  for i, internship in enumerate(sorted(new_ai), 1):
                      parts = internship.split('|')
                      company = parts[0]
                      role = parts[1]
                      location = parts[2]
                      app_link = parts[3] if len(parts) > 3 else ""
                      
                      email_body += f"{i}. {company}\n"
                      email_body += f"   Role: {role}\n"
                      email_body += f"   Location: {location}\n"
                      if app_link:
                          email_body += f"   üîó Apply: {app_link}\n"
                      email_body += "\n"
              
              email_body += "\n" + "=" * 70 + "\n"
              email_body += "üîó View full repository: https://github.com/SimplifyJobs/Summer2026-Internships\n"
              email_body += f"üìä Total SWE roles: {len(swe_internships_new)} | Total AI/ML/DS roles: {len(ai_internships_new)}\n"
              
              # Save email body to file
              with open('email_body.txt', 'w', encoding='utf-8') as f:
                  f.write(email_body)
              
              # Set output for GitHub Actions
              with open('$GITHUB_OUTPUT', 'a') as f:
                  f.write('changes_detected=true\n')
                  f.write(f'new_count={len(new_swe) + len(new_ai)}\n')
                  f.write(f'commit_date={commit_date}\n')
          else:
              print("\n‚ùå No new relevant internships found")
              with open('$GITHUB_OUTPUT', 'a') as f:
                  f.write('changes_detected=false\n')
          
          print("\nAnalysis complete!")
          
          PYTHON_SCRIPT
      
      - name: Send email notification
        if: steps.analyze.outputs.changes_detected == 'true'
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "üö® ${{ steps.analyze.outputs.new_count }} New Summer 2026 Internships!"
          to: ss20355@nyu.edu
          from: Internship Monitor
          body: file://email_body.txt
          
      - name: Update stored README
        if: steps.analyze.outputs.changes_detected == 'true'
        run: |
          cp new_readme.md previous_readme.md
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          git add previous_readme.md
          git commit -m "Update tracked README - ${{ steps.analyze.outputs.new_count }} new internships [skip ci]"
          git push
